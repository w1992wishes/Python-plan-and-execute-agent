from state import AgentState, Plan, PlanStep, PlanType
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage
import json
import re
import time
from logger_config import logger
from prompt_setting import get_replanning_system_prompt
from settings import Settings
from agent_tools import get_all_tools, get_tools_map
from langchain_openai import ChatOpenAI


def _parse_replan(plan_text: str, original_plan: Plan, available_tools: list) -> Plan:
    """è§£æLLMè¿”å›çš„é‡æ–°è§„åˆ’æ–‡æœ¬"""
    try:
        # æå–JSONç‰‡æ®µï¼ˆå‡è®¾LLMæŒ‰æ ¼å¼è¿”å›ï¼‰
        json_part = re.split(r"<\/think>", plan_text)[-1].strip()
        plan_data = json.loads(json_part)

        # éªŒè¯æ ¸å¿ƒå­—æ®µå®Œæ•´æ€§
        required_fields = ["id", "query", "goal", "plan_type", "steps"]
        for field in required_fields:
            if field not in plan_data:
                raise ValueError(f"é‡æ–°è§„åˆ’æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")

        # æ„å»ºæ­¥éª¤å¯¹è±¡
        steps = []
        for i, step_data in enumerate(plan_data["steps"]):
            step = PlanStep(
                id=step_data.get("id", f"step_{i + 1}"),
                description=step_data.get("description", ""),
                tool=step_data.get("tool", ""),
                tool_args=step_data.get("tool_args", {}),
                input_template=step_data.get("input_template", ""),
                dependencies=step_data.get("dependencies", []),
                expected_output=step_data.get("expected_output", ""),
                confidence=step_data.get("confidence", 0.7)
            )

            # è¿‡æ»¤ä¸å¯ç”¨å·¥å…·
            if step.tool and step.tool not in available_tools:
                logger.warning(f"é‡æ–°è§„åˆ’ä¸­å­˜åœ¨ä¸å¯ç”¨å·¥å…·: {step.tool}ï¼Œå·²æ¸…ç©º")
                step.tool = ""  # æ¸…ç©ºæ— æ•ˆå·¥å…·

            steps.append(step)

        # æ„å»ºå®Œæ•´è®¡åˆ’ï¼ˆç»§æ‰¿åŸå§‹è®¡åˆ’çš„æ ¸å¿ƒå±æ€§ï¼‰
        return Plan(
            id=plan_data.get("id", f"replan_{int(time.time())}"),
            query=plan_data.get("query", original_plan.query),
            goal=plan_data.get("goal", original_plan.goal),
            plan_type=PlanType(plan_data.get("plan_type", original_plan.plan_type.value)),
            steps=steps,
            estimated_duration=plan_data.get("estimated_duration", original_plan.estimated_duration),
            confidence=plan_data.get("confidence", original_plan.confidence * 0.9),  # ç½®ä¿¡åº¦è¡°å‡
            metadata={
                "replan_reason": plan_data.get("replan_reason", "è‡ªåŠ¨è°ƒæ•´"),
                "based_on_execution": True
            },
            created_at=time.time()
        )

    except Exception as e:
        logger.error(f"é‡æ–°è§„åˆ’è§£æå¤±è´¥: {e}", exc_info=True)
        raise


def _create_replanning_prompt(
        query: str,
        original_plan: Plan,
        executed_steps: list,
        step_results: dict,
        replan_analysis: dict,
        tools_str: str
) -> str:
    """æ„å»ºé‡æ–°è§„åˆ’çš„Promptï¼ˆå«æ‰§è¡Œä¸Šä¸‹æ–‡å’Œçº¦æŸï¼‰"""
    # æ ¼å¼åŒ–å·²æ‰§è¡Œæ­¥éª¤ï¼ˆå¸¦æˆªæ–­ç»“æœï¼‰
    executed_steps_str = []
    for step_id, result in step_results.items():
        step = next((s for s in original_plan.steps if s.id == step_id), None)
        if step:
            result_str = str(result)
            truncated = result_str[:200] + ("..." if len(result_str) > 200 else "")
            executed_steps_str.append(
                f"æ­¥éª¤ {step.id}: {step.description}\n"
                f" - å·¥å…·: {step.tool}\n"
                f" - ç»“æœ: {truncated}"
            )

    # æ ¼å¼åŒ–æœªæ‰§è¡Œæ­¥éª¤ï¼ˆå¸¦ä¾èµ–ï¼‰
    remaining_steps = [s for s in original_plan.steps if s.id not in step_results]
    remaining_steps_str = []
    for step in remaining_steps:
        remaining_steps_str.append(
            f"æ­¥éª¤ {step.id}: {step.description}\n"
            f" - å·¥å…·: {step.tool}\n"
            f" - ä¾èµ–: {', '.join(step.dependencies) if step.dependencies else 'æ— '}"
        )

    # é—®é¢˜åˆ†ææ¨¡å—
    need_replan = replan_analysis.get("need_replan", False)
    reason = replan_analysis.get("reason", "æœªçŸ¥")
    issues = replan_analysis.get("issues", [])
    suggestions = replan_analysis.get("suggested_adjustments", [])

    return f"""### ä»»åŠ¡é‡è§„åˆ’éœ€æ±‚
æ ¹æ®**æ‰§è¡Œç»“æœ**å’Œ**é—®é¢˜åˆ†æ**ï¼Œç”Ÿæˆ**è°ƒæ•´åçš„æ‰§è¡Œè®¡åˆ’**ï¼Œéœ€æ»¡è¶³ï¼š  
1. ä¿®å¤å·²å‘ç°çš„é—®é¢˜ï¼ˆå¦‚æ­¥éª¤å¤±è´¥ã€ç»“æœå¼‚å¸¸ï¼‰  
2. ä¿æŒä¸åŸå§‹ç›®æ ‡ä¸€è‡´ï¼Œä¿®æ­£æ­¥éª¤ä¾èµ–å…³ç³»  
3. æ ‡æ³¨**é‡è§„åˆ’åŸå› **ï¼Œè¯„ä¼°æ–°è®¡åˆ’ç½®ä¿¡åº¦ï¼ˆå¯ç•¥ä½äºåŸè®¡åˆ’ï¼‰  


### åŸå§‹ä»»åŠ¡ä¸Šä¸‹æ–‡
#### åŸå§‹æŸ¥è¯¢  
{query}  

#### åŸå§‹è®¡åˆ’æ¦‚è¦  
- ç›®æ ‡: {original_plan.goal}  
- ç±»å‹: {original_plan.plan_type.value}  
- æ€»æ­¥éª¤: {len(original_plan.steps)}  
- ç½®ä¿¡åº¦: {original_plan.confidence:.2f}  


### æ‰§è¡ŒçŠ¶æ€åé¦ˆ  
#### å·²æ‰§è¡Œæ­¥éª¤ï¼ˆå¸¦ç»“æœï¼‰  
{('\n\n'.join(executed_steps_str)) if executed_steps_str else 'æ— '}  

#### æœªæ‰§è¡Œæ­¥éª¤ï¼ˆå¸¦ä¾èµ–ï¼‰  
{('\n\n'.join(remaining_steps_str)) if remaining_steps_str else 'æ— '}  


### é—®é¢˜åˆ†æ  
- æ˜¯å¦éœ€è¦é‡è§„åˆ’: {"æ˜¯" if need_replan else "å¦"}  
- é‡è§„åˆ’åŸå› : {reason}  
- å…·ä½“é—®é¢˜: {('\n- ' + '\n- '.join(issues)) if issues else 'æ— '}  
- å»ºè®®è°ƒæ•´: {('\n- ' + '\n- '.join(suggestions)) if suggestions else 'æ— '}  


### å¯ç”¨å·¥å…·ï¼ˆå…± {len(tools_str.splitlines())} ä¸ªï¼‰  
{tools_str}  


### è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªJSONï¼‰  
```json  
{{  
  "id": "å”¯ä¸€è®¡åˆ’ID",  
  "query": "ç”¨æˆ·åŸå§‹æŸ¥è¯¢",  
  "goal": "è®¡åˆ’ç›®æ ‡",  
  "plan_type": "sequential/parallel",  
  "replan_reason": "é‡è§„åˆ’åŸå› ",  
  "steps": [  
    {{  
      "id": "step_1",  
      "description": "æ­¥éª¤æè¿°",  
      "tool": "å·¥å…·åç§°",  
      "tool_args": "å·¥å…·å…¥å‚ï¼ˆæ”¯æŒå¼•ç”¨å‰ç½®æ­¥éª¤ç»“æœï¼‰",  
      "input_template": "è¾“å…¥æ¨¡æ¿ï¼ˆå¦‚ {{city}} çš„å¤©æ°”ï¼‰",  
      "dependencies": ["ä¾èµ–æ­¥éª¤ID"],  
      "expected_output": "é¢„æœŸè¾“å‡º",  
      "confidence": 0.8  
    }}  
  ],  
  "estimated_duration": 60,  // é¢„è®¡è€—æ—¶ï¼ˆç§’ï¼‰  
  "confidence": 0.8,         // æ–°è®¡åˆ’ç½®ä¿¡åº¦  
  "created_at": {int(time.time())}  // æ—¶é—´æˆ³  
}}  
```"""


class ReplanGenerator:
    """é‡è§„åˆ’ç”Ÿæˆå™¨ï¼ˆå°è£…LLMè°ƒç”¨å’Œç»“æœè§£æï¼‰"""

    def __init__(self):
        self.tools = get_all_tools()  # åŠ è½½æ‰€æœ‰å¯ç”¨å·¥å…·
        self.tools_str = "\n".join([f"- {tool.name}: {tool.description}" for tool in self.tools])
        self.tools_map = get_tools_map()  # å·¥å…·æ˜ å°„è¡¨

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.model = ChatOpenAI(
            model=Settings.LLM_MODEL,
            temperature=Settings.TEMPERATURE,
            api_key=Settings.OPENAI_API_KEY,
            base_url=Settings.OPENAI_BASE_URL,
        )

    def generate_replan(
            self,
            query: str,
            original_plan: Plan,
            executed_steps: list,
            step_results: dict,
            replan_analysis: dict
    ) -> Plan:
        """ç”Ÿæˆè°ƒæ•´åçš„æ‰§è¡Œè®¡åˆ’"""
        # æ„å»ºPrompt
        prompt = _create_replanning_prompt(
            query=query,
            original_plan=original_plan,
            executed_steps=executed_steps,
            step_results=step_results,
            replan_analysis=replan_analysis,
            tools_str=self.tools_str
        )

        # è°ƒç”¨LLM
        messages = [
            SystemMessage(content=get_replanning_system_prompt()),  # ç³»ç»Ÿæç¤ºï¼ˆæ¥è‡ªprompt_settingï¼‰
            HumanMessage(content=prompt)
        ]
        response = self.model.invoke(messages)
        logger.info(f"é‡è§„åˆ’LLMå“åº”: \n{response.content}")

        # è§£æå¹¶è¿”å›æ–°è®¡åˆ’
        return _parse_replan(
            plan_text=response.content,
            original_plan=original_plan,
            available_tools=[t.name for t in self.tools]
        )


def replan_node(state: AgentState) -> dict:
    """LangGraphèŠ‚ç‚¹ï¼šæ ¹æ®æ‰§è¡Œç»“æœåŠ¨æ€è°ƒæ•´ä»»åŠ¡è®¡åˆ’"""
    logger.info("ğŸ”„ é‡è§„åˆ’èŠ‚ç‚¹å¯åŠ¨ï¼Œåˆ†ææ‰§è¡Œç»“æœ...")

    # æå–å½“å‰çŠ¶æ€
    replan_count = state.get("replan_count", 0)
    current_plan = state.get("current_plan")
    step_results = state.get("step_results", {})
    executed_steps = list(step_results.keys())
    replan_analysis = state.get("replan_analysis", {})

    # é‡è§„åˆ’æ¬¡æ•°ä¸Šé™æ ¡éªŒï¼ˆç¤ºä¾‹ï¼šå…è®¸1æ¬¡é‡è§„åˆ’ï¼Œå¯é…ç½®ï¼‰
    if replan_count >= 1:
        logger.error("âš ï¸ è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°ï¼Œç»ˆæ­¢ä»»åŠ¡è°ƒæ•´")
        return {
            "replan_limit": True,
            "replan_count": replan_count,
            "messages": state.get("messages", []) + [
                AIMessage(content="å¤šæ¬¡é‡è§„åˆ’å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œä»»åŠ¡")
            ]
        }

    try:
        # ç”Ÿæˆæ–°è®¡åˆ’
        generator = ReplanGenerator()
        new_plan = generator.generate_replan(
            query=state["input"],
            original_plan=current_plan,
            executed_steps=executed_steps,
            step_results=step_results,
            replan_analysis=replan_analysis
        )

        # æ›´æ–°çŠ¶æ€
        replan_count += 1
        logger.info(
            f"âœ… é‡è§„åˆ’æˆåŠŸ | æ–°è®¡åˆ’ID: {new_plan.id} | æ­¥éª¤æ•°: {len(new_plan.steps)} | é‡è§„åˆ’æ¬¡æ•°: {replan_count}"
        )
        print(f"Generated Replan:\n{new_plan}")

        return {
            "current_plan": new_plan,
            "plan_history": state.get("plan_history", []) + [new_plan],
            "replan_limit": False,
            "replan_count": replan_count,
            "messages": state.get("messages", []) + [
                AIMessage(content=f"å·²æ ¹æ®æ‰§è¡Œç»“æœè°ƒæ•´è®¡åˆ’ï¼š\n{new_plan}")
            ]
        }

    except Exception as e:
        # å¼‚å¸¸å¤„ç†ï¼šè®°å½•æ—¥å¿—ï¼Œä¿ç•™å½“å‰è®¡åˆ’
        logger.exception(f"âŒ é‡è§„åˆ’å¤±è´¥: {str(e)}")
        return {
            "current_plan": current_plan,
            "replan_limit": True,
            "replan_count": replan_count,
            "messages": state.get("messages", []) + [
                AIMessage(content=f"é‡è§„åˆ’å¼‚å¸¸ï¼š{str(e)}ï¼Œä¿ç•™å½“å‰è®¡åˆ’é‡è¯•")
            ]
        }