from agent_tools import get_all_tools
from logger_config import logger
from langchain_openai import ChatOpenAI
from settings import Settings
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, ToolMessage
from typing import TypedDict, Annotated, List, Sequence
import operator
import json
from langchain.tools.render import render_text_description
from langgraph.graph import StateGraph, END  # å›¾æ„å»ºä¾èµ–
from pprint import pprint

class ReActAgentState(TypedDict):
    """å®šä¹‰ Agent åœ¨å›¾ä¸­çš„çŠ¶æ€ï¼Œæ‰€æœ‰èŠ‚ç‚¹å…±äº«å’Œä¿®æ”¹æ­¤çŠ¶æ€ã€‚"""
    messages: Annotated[Sequence[BaseMessage], operator.add]


class ReActAgent:
    def __init__(self, model: ChatOpenAI, tools: List, system_message: str | None = None):
        """
        åˆå§‹åŒ– Agentã€‚
        - model: ç»‘å®šå·¥å…·çš„ LangChain Chat Model å®ä¾‹
        - tools: LangChain å·¥å…·å®ä¾‹åˆ—è¡¨
        """
        self.model = model
        self.tools = tools
        self.tools_map = {t.name: t for t in tools}  # å·¥å…·åç§°æ˜ å°„
        self.graph = self._build_graph()
        self.conversation_history = []  # å¯¹è¯å†å²å­˜å‚¨
        self.system_message = SystemMessage(content=system_message) if system_message else None

    def _build_graph(self) -> StateGraph:
        """æ„å»ºå¹¶ç¼–è¯‘ LangGraph å›¾ã€‚"""
        workflow = StateGraph(ReActAgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent_llm", self._call_model)
        workflow.add_node("action", self._call_tool)

        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("agent_llm")

        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent_llm",
            self._should_continue,
            {
                "continue": "action",
                "end": END,
            },
        )

        # æ·»åŠ æ™®é€šè¾¹
        workflow.add_edge("action", "agent_llm")

        # ç¼–è¯‘å›¾
        return workflow.compile()

    def _call_model(self, state: ReActAgentState) -> dict:
        """
        ç§æœ‰æ–¹æ³•ï¼šè°ƒç”¨å¤§æ¨¡å‹ã€‚
        è¿™æ˜¯å›¾ä¸­çš„ "agent_llm" èŠ‚ç‚¹ã€‚
        """
        messages = state['messages']
        print(f"llm message: {messages}")
        model_with_tools = self.model.bind_tools(self.tools)
        response = model_with_tools.invoke(messages)
        # ç»Ÿè®¡ token ä½¿ç”¨æƒ…å†µ
        return {"messages": [response]}

    def _call_tool(self, state: ReActAgentState) -> dict:
        """
        ç§æœ‰æ–¹æ³•ï¼šè°ƒç”¨å·¥å…·ã€‚
        è¿™æ˜¯å›¾ä¸­çš„ "action" èŠ‚ç‚¹ã€‚
        """
        last_message = state['messages'][-1]
        print(f"tool message: {last_message}")

        if not last_message.tool_calls:
            return {}

        tool_messages = []
        for tool_call in last_message.tool_calls:
            tool_name = tool_call['name']
            if tool_name in self.tools_map:
                tool_to_call = self.tools_map[tool_name]
                try:
                    # è°ƒç”¨å·¥å…·å¹¶è·å–è¾“å‡º
                    tool_output = tool_to_call.invoke(tool_call['args'])
                    # å°†ç»“æ„åŒ–è¾“å‡ºåºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²
                    tool_output_str = json.dumps(tool_output, ensure_ascii=False)

                    tool_messages.append(
                        ToolMessage(
                            content=tool_output_str,
                            tool_call_id=tool_call['id'],
                        )
                    )
                except Exception as e:
                    error_msg = f"Error executing tool {tool_name}: {e}"
                    tool_messages.append(
                        ToolMessage(content=error_msg, tool_call_id=tool_call['id'])
                    )
            else:
                # å¦‚æœæ¨¡å‹å°è¯•è°ƒç”¨ä¸€ä¸ªä¸å­˜åœ¨çš„å·¥å…·
                error_msg = f"Tool '{tool_name}' not found."
                tool_messages.append(
                    ToolMessage(content=error_msg, tool_call_id=tool_call['id'])
                )

        return {"messages": tool_messages}

    def _should_continue(self, state: ReActAgentState) -> str:
        """
        ç§æœ‰æ–¹æ³•ï¼šå†³ç­–ä¸‹ä¸€æ­¥èµ°å‘ã€‚
        è¿™æ˜¯å›¾ä¸­çš„æ¡ä»¶è¾¹é€»è¾‘ã€‚
        """
        last_message = state['messages'][-1]
        if last_message.tool_calls:
            return "continue"
        else:
            return "end"

    def run(self, query: str, stream: bool = True) -> str:
        """
        è¿è¡Œ Agent å¤„ç†å•ä¸ªæŸ¥è¯¢ã€‚
        - query: ç”¨æˆ·çš„è¾“å…¥é—®é¢˜ã€‚
        - stream: æ˜¯å¦æµå¼æ‰“å°ä¸­é—´æ­¥éª¤ (é»˜è®¤ä¸º True)ã€‚
        è¿”å› Agent çš„æœ€ç»ˆå›ç­”ã€‚
        """
        initial_messages = [self.system_message] if self.system_message else []
        current_messages = initial_messages + self.conversation_history + [HumanMessage(content=query)]
        inputs = {"messages": current_messages}

        final_answer = ""  # åˆå§‹åŒ–ä¸€ä¸ªå˜é‡æ¥å­˜å‚¨æœ€ç»ˆç­”æ¡ˆ

        if stream:
            print(f"--- Running query: {query} ---\n")

            # --- åªè¿è¡Œä¸€æ¬¡å›¾ ---
            for output in self.graph.stream(inputs):
                # 1. æ‰“å°æ—¥å¿—ï¼ˆä¿æŒä¸å˜ï¼‰
                print("--- Node Output ---")
                pprint(output)
                print("\n")

                # 2. æ™ºèƒ½æ•è·æœ€ç»ˆç­”æ¡ˆ
                # æœ€ç»ˆç­”æ¡ˆçš„ç‰¹å¾æ˜¯ï¼šå®ƒæ¥è‡ªäº'agent_llm'èŠ‚ç‚¹ï¼Œå¹¶ä¸”ä¸åŒ…å«å·¥å…·è°ƒç”¨
                for key, value in output.items():
                    if key == 'agent_llm':
                        # æ£€æŸ¥ 'agent_llm' èŠ‚ç‚¹çš„è¾“å‡ºä¸­æ˜¯å¦æœ‰æ¶ˆæ¯
                        messages = value.get('messages', [])
                        if messages:
                            last_message = messages[-1]
                            # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯ä¸æ˜¯å·¥å…·è°ƒç”¨ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯æœ€ç»ˆç­”æ¡ˆ
                            if not last_message.tool_calls:
                                final_answer = last_message.content
            if final_answer:
                # 1. è·å–å½“å‰ç”¨æˆ·çš„æé—®
                user_message = HumanMessage(content=query)
                # 2. å°†æœ€ç»ˆç­”æ¡ˆåŒ…è£…æˆ AIMessage
                agent_message = AIMessage(content=final_answer)
                # 3. å°†è¿™ä¸€å¯¹ Q&A è¿½åŠ åˆ°é•¿æœŸå†å²ä¸­
                self.conversation_history.extend([user_message, agent_message])
            return final_answer

        else:
            # éæµå¼æ¨¡å¼ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒåªè¿è¡Œä¸€æ¬¡ invoke
            final_state = self.graph.invoke(inputs)
            user_message = HumanMessage(content=query)
            agent_message = AIMessage(content=final_state['messages'][-1].content)
            self.conversation_history.extend([user_message, agent_message])
            return final_state['messages'][-1].content


def create_agent(plan_steps: str):
    """åˆ›å»º ReAct æ™ºèƒ½ä½“ï¼ˆæ³¨å…¥ä»»åŠ¡æ¸…å•å’Œå·¥å…·ï¼‰"""
    tools = get_all_tools()
    rendered_tools = render_text_description(tools)

    # æ„é€ ç³»ç»Ÿæç¤ºï¼ˆå«ä»»åŠ¡æµç¨‹ã€å·¥å…·ã€æ ¼å¼çº¦æŸï¼‰
    system_prompt = f"""ä½ æ˜¯éå¸¸é è°±çš„ä»»åŠ¡æ‰§è¡ŒåŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼éµå®ˆä»»åŠ¡æ¸…å•ï¼ŒæŒ‰ç…§é¡ºåºè°ƒç”¨å·¥å…·è¿›è¡Œæ‰§è¡Œï¼š

å¯ç”¨å·¥å…·åˆ—è¡¨ï¼š
\n{rendered_tools}\n

ä»»åŠ¡æ¸…å•ï¼š
\n{plan_steps}\n

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™æ‰§è¡Œï¼š
1. ä¸¥æ ¼æŒ‰ç…§ä»»åŠ¡æ¸…å•é¡ºåºæ‰§è¡Œï¼Œä¸èƒ½è·³è¿‡æˆ–æ›´æ”¹é¡ºåº
2. æ¯æ¬¡åªèƒ½è°ƒç”¨ä¸€ä¸ªå·¥å…·ï¼Œç­‰å¾…å·¥å…·ç»“æœè¿”å›åå†ç»§ç»­
3. å·¥å…·è°ƒç”¨åï¼Œå¿…é¡»åæ€å·¥å…·ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å°†ä»ä»»åŠ¡ç»“æœä¸­å–å‡ºæ•°æ®æ”¾åˆ°ä¸‹ä¸€æ­¥çš„ä»»åŠ¡å‚æ•°ä¸­ï¼Œä¸èƒ½ç›²ç›®æ‰§è¡Œ
4. å¦‚æœä»»åŠ¡æ¸…å•ä¸­æŸæ­¥æ²¡æœ‰æŒ‡å®šå·¥å…·æˆ–æŸæ­¥æŒ‡å®šçš„å·¥å…·ä¸å­˜åœ¨ï¼Œåˆ™æ€è€ƒåè·³è¿‡è¯¥æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
5. å¦‚æœä»»åŠ¡æ¸…å•ä¸­æ‰€æœ‰æ­¥éª¤éƒ½æ‰§è¡Œå®Œæ¯•ï¼Œåˆ™æ€è€ƒåç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
""".strip()

    # åˆå§‹åŒ–å¤§æ¨¡å‹
    llm = ChatOpenAI(
        model=Settings.LLM_MODEL,
        temperature=Settings.TEMPERATURE,
        api_key=Settings.OPENAI_API_KEY,
        base_url=Settings.OPENAI_BASE_URL,
    )
    return ReActAgent(model=llm, tools=tools, system_message=system_prompt)


from state import AgentState
from langchain_core.messages import AIMessage
import traceback


# ... å…¶ä»–å·²æœ‰å¯¼å…¥ ...


def action_executor_node(state: AgentState) -> dict:
    """LangGraph èŠ‚ç‚¹ï¼šæ‰§è¡Œ ReAct æ™ºèƒ½ä½“ï¼Œå«å¼‚å¸¸å¤„ç†ä¸é‡è§„åˆ’æ ‡è®°"""
    logger.info("ğŸš€ğŸ¤– ReAct æ™ºèƒ½ä½“å¯åŠ¨ï¼Œå¼€å§‹æ‰§è¡Œä»»åŠ¡")
    current_plan = state.get("current_plan")

    # æ— ä»»åŠ¡è®¡åˆ’çš„å¿«é€Ÿå¤±è´¥
    if not current_plan:
        logger.warning("æ— æœ‰æ•ˆæ‰§è¡Œè®¡åˆ’ï¼Œç›´æ¥è¿”å›å¤±è´¥")
        return {"messages": [AIMessage(content="æ— æ³•æ‰§è¡Œï¼šå½“å‰æ— ä»»åŠ¡è®¡åˆ’")]}

    # æ„å»ºå¸¦çŠ¶æ€å’Œä¾èµ–çš„ä»»åŠ¡æ¸…å•
    plan_steps_text = "ä»»åŠ¡æ¸…å•ï¼š\n"
    for i, step in enumerate(current_plan.steps):
        status = "â³"
        plan_steps_text += f"{i + 1}. [{status}] {step.description}"

        # é™„åŠ å·¥å…·ä¿¡æ¯
        if step.tool:
            plan_steps_text += f"ï¼ˆå·¥å…·ï¼š{step.tool}ï¼‰"
        plan_steps_text += "\n"

        # ä¾èµ–è¯´æ˜ï¼ˆéé¦–æ­¥æ·»åŠ ä¾èµ–æç¤ºï¼‰
        if i > 0:
            plan_steps_text += f"  ä¾èµ–ï¼šæ­¥éª¤ {i} çš„ç»“æœå¯èƒ½å½±å“å½“å‰æ­¥éª¤å‚æ•°\n"

    try:
        # åˆ›å»ºæ™ºèƒ½ä½“å¹¶æ‰§è¡Œä»»åŠ¡
        agent = create_agent(plan_steps_text)
        input_text = (
            f"ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼š{state['input']}\n"
            f"æ‰§è¡Œç›®æ ‡ï¼š{current_plan.goal}\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»»åŠ¡æ¸…å•é¡ºåºæ‰§è¡Œï¼Œä»»åŠ¡å®Œæˆååæ€ç»“æœå¹¶åŠ¨æ€è°ƒæ•´å‚æ•°ã€‚"
        )
        logger.info(f"ğŸ“¥ æ™ºèƒ½ä½“è¾“å…¥ï¼š\n{input_text}")
        logger.info(f"ğŸ“‹ ä»»åŠ¡æ¸…å•ï¼š\n{plan_steps_text}")

        result = agent.run(input_text)
        # ç»„è£…è¿”å›æ¶ˆæ¯ï¼ˆå«æ‰§è¡Œç»“æœï¼‰
        messages = state.get("messages", []) + [AIMessage(content=result)]
        logger.info(f"âœ… æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆ | è¾“å‡ºé¢„è§ˆï¼š{result[:50]}...")

        return {
            "output": result,
            "messages": messages
        }

    except Exception as e:
        # å¼‚å¸¸æ•è·ï¼šè®°å½•æ ˆä¿¡æ¯ + è¿”å›é‡è§„åˆ’æ ‡è®°
        logger.error(f"âŒ æ™ºèƒ½ä½“æ‰§è¡Œå¤±è´¥ï¼š{str(e)}", exc_info=True)
        return {
            "messages": [
                AIMessage(
                    content=f"æ™ºèƒ½ä½“æ‰§è¡Œå¤±è´¥ï¼š{str(e)}",
                    additional_kwargs={"error": traceback.format_exc()}  # é™„åŠ å®Œæ•´æ ˆä¿¡æ¯
                )
            ],
            "need_replan": True  # æ ‡è®°éœ€è¦é‡è§„åˆ’
        }